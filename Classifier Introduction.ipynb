{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bb10a5-277f-4467-9fcb-bc9af3108fa3",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c62fe-f6ab-4e14-8e3f-70da4e67b86a",
   "metadata": {},
   "source": [
    "In this notebook we introduce the methodology of using an open source language model (classifier) to classify strings into a set of arbitrary categories. \n",
    "\n",
    "The language model we will use is pretrained on a large dataset (just like the models underpinning OpenAI's recently famous ChatGPT interface). This model in particular has been trained and released by Facebook and has been optimized on the task of classification instead of text generation, but the underlying techniques are similar. It therefore is able to perform the tasks we want directly out-of-the-box without any further tweaking!\n",
    "\n",
    "Classification is the act of assigning a probability between one and zero to a (set of) label(s) being applicable to a string of text. \n",
    "\n",
    "To give an example, the sentence \"The sun is out today.\" seems pretty happy. If a person were asked to give it a score on \"happiness\", they might assign it a score of 90%. But what about the sentence \"It is raining outside..\"? That perhaps should score only 10%, if not lower. The language model we use will be able to draw similar conclusions automatically based on it's understanding of the English language.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffab154-1832-452b-b636-454dba5c6f37",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdb8a69-93ef-4259-99b6-0b6bcd4914f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline helper from the transformers package, which we will use to load our model\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9282ec5a-959b-4ae3-a240-2ec3bf0da407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and instantiate the facebook/bart-large-mlni model and pipeline. The first time this cell runs, it downloads a large file containing the model weights (1.5GB of parameters all in all!). \n",
    "# Let it finish and from then on it will be cached on disk.\n",
    "\n",
    "# Stay aware that this model instantiation uses a lot of memory/RAM, as it has to load the full 1.5GB of model parameters. If you load the model as below in several notebooks at the same time, you might overload your box. \n",
    "# To avoid this, when you're done with a notebook, close it's \"kernel\" on the left side of the Jupyterlabs interface (The second icon. circle with a square inside, selects the active kernels). This unloads the model from memory.\n",
    "\n",
    "c = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60d6557-54a4-4909-8e04-1db2efe6a392",
   "metadata": {},
   "source": [
    "# Testing whether a label is applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f345799-94c9-469a-b5e8-c50b5f215543",
   "metadata": {},
   "source": [
    "Let's see if we can replicate the ideas above. Is the sentence \"The sun is out today!\" indeed classifiably happy?\n",
    "\n",
    "To do so, we use the defined interface of our classifier, which takes (at least) the following arguments: a sentence, a list of labels.\n",
    "\n",
    "Perhaps it's easier to just look at an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66500d8-9997-4607-85a7-b9c5d309cd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'The sun is out today.',\n",
       " 'labels': ['Happy'],\n",
       " 'scores': [0.958601176738739]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('The sun is out today.', ['Happy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929fea5-d565-4f71-ac7d-65d22f78b1f5",
   "metadata": {},
   "source": [
    "Great result! It looks like our sentence is indeed very happy. With a score of almost 96%, it doesn't get much happier than that.\n",
    "\n",
    "Challenge: Can you find a way to modify the sentence such that it is even happier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e373e50-9430-412f-9608-7242e9fa7b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'The sun is out today.',\n",
       " 'labels': ['Happy'],\n",
       " 'scores': [0.958601176738739]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify the sentence to something even happier\n",
    "c('The sun is out today.', ['Happy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09d4a4-dd0d-44da-8f31-da7e66758015",
   "metadata": {},
   "source": [
    "And how about our \"unhappy\" sentence, will it indeed agree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6676ad-381d-4ad0-8037-5fec1ac00fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'It is raining outside..',\n",
       " 'labels': ['Happy'],\n",
       " 'scores': [0.00019142446399200708]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('It is raining outside..', ['Happy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2332b4-71b1-4f3e-9703-910abfa25d41",
   "metadata": {},
   "source": [
    "Nobody likes rain.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf869ae-03e7-48d2-8f41-98bd9ce67d7e",
   "metadata": {},
   "source": [
    "# Multiple labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f32bb-e819-4081-8186-d75cbd376962",
   "metadata": {},
   "source": [
    "If that's not a happy sentence, then perhaps we can conclude it's a sad one? Does our model agree?\n",
    "\n",
    "We can ask it to make a choice between several available labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8183e66-5fac-415a-a9c8-7b80efd5a7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'It is raining outside..',\n",
       " 'labels': ['Sad', 'Happy'],\n",
       " 'scores': [0.9559348821640015, 0.04406508430838585]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('It is raining outside..', ['Happy', 'Sad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0417f3b-b1e1-4f72-b653-b78281b620c8",
   "metadata": {},
   "source": [
    "The mathematics of the model work out slightly differently to before for multi-labeling, but the conclusion remains the same, it certainly considers the sentence to be much more sad than happy.\n",
    "\n",
    "What about other labels, like wet, dry, high, low and colorful or gray?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1a133-fa29-4cb8-b868-0fd6cb10cc4b",
   "metadata": {},
   "source": [
    "c('It is raining outside..', ['Happy', 'Sad', 'Wet', 'Dry', 'High', 'Low', 'Colorful', 'Gray'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f9bcf-cd67-4339-b700-0d29e9571751",
   "metadata": {},
   "source": [
    "Hard question, but a clear and agreeable answer, it's more Wet than any other of those labels. But isn't rain both wet and sad?\n",
    "\n",
    "To answer that question we can ask the model to assign a probability per label, rather than forcing it to make a choice. Note that in the above result, all label probabilities add up to 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd295c6-e9e9-40b4-9c4a-da2668690408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'It is raining outside..',\n",
       " 'labels': ['Wet', 'Sad', 'Low', 'Gray', 'High', 'Colorful', 'Dry', 'Happy'],\n",
       " 'scores': [0.9990817308425903,\n",
       "  0.8136840462684631,\n",
       "  0.7355218529701233,\n",
       "  0.41334474086761475,\n",
       "  0.03862270340323448,\n",
       "  0.001768096350133419,\n",
       "  0.0003273721958976239,\n",
       "  0.00019142446399200708]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('It is raining outside..', ['Happy', 'Sad', 'Wet', 'Dry', 'High', 'Low', 'Colorful', 'Gray'], multi_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca57c325-c81a-47ab-b04e-46faca0bee23",
   "metadata": {},
   "source": [
    "This makes sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd26a92f-97f6-48e6-90fa-0fabedd11f34",
   "metadata": {},
   "source": [
    "# Edge cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b9579-72ce-4feb-b9b9-d5db2c20c306",
   "metadata": {},
   "source": [
    "Negatiation. Surely, if rain is bad, then the opposite should be good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5214a1f-b06b-4a4d-9b85-e730b5ee759c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'It is not raining outside..',\n",
       " 'labels': ['Happy', 'Sad'],\n",
       " 'scores': [0.8534077405929565, 0.14659228920936584]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('It is not raining outside..', ['Happy', 'Sad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dbc2ff-1a5c-4f2a-a2a1-633be41d1209",
   "metadata": {},
   "source": [
    "It depends on the context though, and the model can handle that pretty well too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc09673c-79a5-4109-b69d-2a6901db4dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'After the drought it is finally raining outside..',\n",
       " 'labels': ['Happy', 'Sad'],\n",
       " 'scores': [0.7387923002243042, 0.2612077295780182]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('After the drought it is finally raining outside..', ['Happy', 'Sad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1db0e4-1dc9-4407-bcdf-b58f26928681",
   "metadata": {},
   "source": [
    "# Multiple sentences/strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a0591-989e-40c9-a6d6-6d6ca536276b",
   "metadata": {},
   "source": [
    "We can also ask the model to classify multiple senteces in one go. That might be useful when you use this model for your trading strategy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10578de-994b-493f-bfc8-6fbfda937c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'The sun is out today.',\n",
       "  'labels': ['Happy', 'Sad'],\n",
       "  'scores': [0.9836673140525818, 0.016332658007740974]},\n",
       " {'sequence': 'It is raining outside..',\n",
       "  'labels': ['Sad', 'Happy'],\n",
       "  'scores': [0.9559348821640015, 0.04406508430838585]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(['The sun is out today.', 'It is raining outside..'], ['Happy', 'Sad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d996a1c-dfbc-49b2-8f39-2da91b030e72",
   "metadata": {},
   "source": [
    "# Free-form exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89654e41-e571-4551-bb43-5afa1ff10cf1",
   "metadata": {},
   "source": [
    "Below, try a few different examples, different labels, sentence structures, and so on, to get a feel for that the model can and can't handle very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48bf1e84-1fbf-4565-9ea0-5e35533cb277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': '@PharmaNews: Pfizer faces backlash over possible closure of regional office. #PharmaNews #RegionalOffice',\n",
       " 'labels': ['PFE', 'sad', 'NVDA', 'CSCO', 'SAN', 'ING'],\n",
       " 'scores': [0.8763680458068848,\n",
       "  0.0623045489192009,\n",
       "  0.017301151528954506,\n",
       "  0.01568964123725891,\n",
       "  0.014519426971673965,\n",
       "  0.013817159458994865]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c('@PharmaNews: Pfizer faces backlash over possible closure of regional office. #PharmaNews #RegionalOffice', ['sad','NVDA', 'ING', 'SAN', 'PFE', 'CSCO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d369e1e4-e0fb-47be-be6e-ca37a031f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4932d0d-1737-4ca5-ac4a-2fd71acdd11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SocialMediaFeed</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>ING</th>\n",
       "      <th>SAN</th>\n",
       "      <th>PFE</th>\n",
       "      <th>CSCO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PharmaNews: Pfizer faces backlash over possib...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@BusinessReport: A recent study found that mos...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@HardwareHubs: NVIDIA's contributions to a maj...</td>\n",
       "      <td>0.026125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@HealthWatch: Johnson &amp; Johnson faces lawsuits...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@IndustryInsider: Magnificent Honary faces pro...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@SocialMediaRumor: Unverified sources hint at ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@USFastFoodNews: McDonald's facing heat over p...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@TechTrends: Cisco faces challenges in its sup...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@DigitalDaily: Nvidia's stock feels the heat a...</td>\n",
       "      <td>-0.030776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@PharmaFlash: Pfizer faces minor product recal...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     SocialMediaFeed      NVDA  ING  SAN  \\\n",
       "0  @PharmaNews: Pfizer faces backlash over possib...  0.000000  0.0  0.0   \n",
       "1  @BusinessReport: A recent study found that mos...  0.000000  0.0  0.0   \n",
       "2  @HardwareHubs: NVIDIA's contributions to a maj...  0.026125  0.0  0.0   \n",
       "3  @HealthWatch: Johnson & Johnson faces lawsuits...  0.000000  0.0  0.0   \n",
       "4  @IndustryInsider: Magnificent Honary faces pro...  0.000000  0.0  0.0   \n",
       "5  @SocialMediaRumor: Unverified sources hint at ...  0.000000  0.0  0.0   \n",
       "6  @USFastFoodNews: McDonald's facing heat over p...  0.000000  0.0  0.0   \n",
       "7  @TechTrends: Cisco faces challenges in its sup...  0.000000  0.0  0.0   \n",
       "8  @DigitalDaily: Nvidia's stock feels the heat a... -0.030776  0.0  0.0   \n",
       "9  @PharmaFlash: Pfizer faces minor product recal...  0.000000  0.0  0.0   \n",
       "\n",
       "        PFE      CSCO  \n",
       "0 -0.029512  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.000000  0.000000  \n",
       "4  0.000000  0.000000  \n",
       "5  0.000000  0.000000  \n",
       "6  0.000000  0.000000  \n",
       "7  0.000000 -0.028257  \n",
       "8  0.000000  0.000000  \n",
       "9  0.000000  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "df = pd.read_csv('training.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61b97fb9-8171-47cf-98e5-9a741eaba45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Stock Movement: -1.0\n",
      "Predicted Sentiment: negative\n",
      "Confidence Score: 0.9809707999229431\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the zero-shot classification pipeline\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "\n",
    "# Function to analyze sentiment and predict stock movement\n",
    "def analyze_sentiment_and_stock(text):\n",
    "    # Define the possible labels (sentiments)\n",
    "    possible_labels = ['positive', 'negative', 'neutral']\n",
    "\n",
    "    # Perform zero-shot classification\n",
    "    result = classifier(text, possible_labels)\n",
    "\n",
    "    # Extract the predicted label and score\n",
    "    predicted_label = result['labels'][0]\n",
    "    predicted_score = result['scores'][0]\n",
    "\n",
    "    # Map sentiment to stock movement\n",
    "    if predicted_label == 'positive':\n",
    "        stock_movement = 1.0  # Replace with actual positive movement\n",
    "    elif predicted_label == 'negative':\n",
    "        stock_movement = -1.0  # Replace with actual negative movement\n",
    "    else:\n",
    "        stock_movement = 0.0  # Neutral sentiment\n",
    "\n",
    "    return stock_movement, predicted_label, predicted_score\n",
    "\n",
    "# Example usage\n",
    "text_example = \"@PharmaNews: Pfizer faces backlash over possible closure of regional office. #PharmaNews #RegionalOffice\"\n",
    "movement, label, score = analyze_sentiment_and_stock(text_example)\n",
    "\n",
    "print(f\"Predicted Stock Movement: {movement}\")\n",
    "print(f\"Predicted Sentiment: {label}\")\n",
    "print(f\"Confidence Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e22be9-4950-4411-9146-c36192b7e960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Company: ING\n",
      "Predicted Sentiment: negative\n",
      "Sentiment Score: 0.813266396522522\n",
      "Adjusted Output: 0.0\n"
     ]
    }
   ],
   "source": [
    "from stock_sentiment_analysis import analyze_sentiment_and_stock\n",
    "\n",
    "# Example usage\n",
    "text_example = \"@FinancialLeaks: Unconfirmed report of operational inefficiencies at ING Bank. #Banking #OperationalInnovation ING\"\n",
    "detected_company, predicted_sentiment, sentiment_score, adjusted_output = analyze_sentiment_and_stock(text_example)\n",
    "\n",
    "print(f\"Detected Company: {detected_company}\")\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
    "print(f\"Sentiment Score: {sentiment_score}\")\n",
    "print(f\"Adjusted Output: {adjusted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a8d4357-5264-4ccf-9c95-aa19598ea338",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_training_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    non_zero_companies = [company for company in ['NVDA', 'ING', 'SAN', 'PFE', 'CSCO'] if row[company] != 0]\n",
    "    if non_zero_companies:\n",
    "        # Use the first non-zero company as the label\n",
    "        label = non_zero_companies[0]\n",
    "    else:\n",
    "        # No non-zero companies, assign an empty label\n",
    "        label = ''\n",
    "\n",
    "    text_data = row['SocialMediaFeed']\n",
    "    company_training_data.append((text_data, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e74751a4-a9d6-414e-90a3-d31c00910802",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-324ec2e09623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-324ec2e09623>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mvectorized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Keep label as a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvectorized_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use .item() to get the integer value if it's numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_data, test_data = train_test_split(company_training_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义简单的文本分类模型\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, 32, sparse=True)\n",
    "        self.fc = nn.Linear(32, output_size)\n",
    "    \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "# 定义数据集类\n",
    "class CompanyDataset(Dataset):\n",
    "    def __init__(self, data, vectorizer):\n",
    "        self.data = data\n",
    "        self.vectorizer = vectorizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text, label = self.data[index]\n",
    "        vectorized_text = torch.tensor(self.vectorizer.transform([text]).toarray()[0])\n",
    "        label = torch.tensor([label], dtype=torch.long)  # Keep label as a string\n",
    "        return vectorized_text, label.item()  # Use .item() to get the integer value if it's numeric\n",
    "\n",
    "# 初始化文本向量化器\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit([text for text, _ in train_data])\n",
    "\n",
    "# 初始化数据集和数据加载器\n",
    "train_dataset = CompanyDataset(train_data, vectorizer)\n",
    "test_dataset = CompanyDataset(test_data, vectorizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = TextClassifier(vocab_size=len(vectorizer.vocabulary_), output_size=len(set(label for _, label in train_data)))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text, None)\n",
    "        \n",
    "        # Ensure labels are converted to LongTensor\n",
    "        label_tensor = torch.tensor([int(label)], dtype=torch.long)  # Convert label to integer\n",
    "        \n",
    "        loss = criterion(output, label_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 评估模型\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for text, label in test_loader:\n",
    "        output = model(text, None)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44041a99-ac5a-4d22-b8e0-5cdf34bb0348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@PharmaNews: Pfizer faces backlash over possible closure of regional office. #PharmaNews #RegionalOffice', 'negative')\n",
      "('@BusinessReport: A recent study found that most CEOs only read business books. That explains a lot. #CEOReads #BusinessBooks', 'neutral')\n",
      "(\"@HardwareHubs: NVIDIA's contributions to a major industry collaboration have given the stock a boost. #IndustryCollaboration #GraphicsChip\", 'positive')\n",
      "('@HealthWatch: Johnson & Johnson faces lawsuits over product safety concerns. #Lawsuits #ProductSafety', 'neutral')\n",
      "('@IndustryInsider: Magnificent Honary faces production delays. #ProductionDelays #IndustryNews', 'neutral')\n"
     ]
    }
   ],
   "source": [
    "sentiment_training_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # 计算五个公司的数值和\n",
    "    total_value = sum(row[['NVDA', 'ING', 'SAN', 'PFE', 'CSCO']])\n",
    "    \n",
    "    # 根据数值和的正负性分配标签\n",
    "    sentiment_label = 'positive' if total_value > 0 else ('negative' if total_value < 0 else 'neutral')\n",
    "    \n",
    "    text_data = row['SocialMediaFeed']\n",
    "    sentiment_training_data.append((text_data, sentiment_label))\n",
    "\n",
    "# 打印示例数据\n",
    "for example in sentiment_training_data[:5]:\n",
    "    print(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44a6545-a80e-4dcf-91a4-ba51b1a3df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"testmodel.py\", line 71, in <module>\n",
      "    loss = criterion(output, label)\n",
      "  File \"/home/ec2-user/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/ec2-user/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 1152, in forward\n",
      "    label_smoothing=self.label_smoothing)\n",
      "  File \"/home/ec2-user/.local/lib/python3.6/site-packages/torch/nn/functional.py\", line 2846, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "TypeError: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not tuple\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97121f-eb36-48fb-9cae-866f25e7d9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
